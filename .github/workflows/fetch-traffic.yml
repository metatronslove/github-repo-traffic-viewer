name: GitHub Traffic Data Collector

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  fetch-traffic-data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install pygithub==1.59.0
          python -m pip install pyyaml

      - name: Clean and setup
        run: |
          # Sadece eski trafik verilerini sil, repo-info.json koru
          find docs/data/repos/ -mindepth 1 -maxdepth 1 -type d -exec rm -rf {} +
          mkdir -p docs/data/repos
          echo "DATA_DIR=docs/data" >> $GITHUB_ENV

      - name: Collect traffic data
        env:
          GH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
        run: |
          python - <<EOF
          from github import Github
          import os
          import json
          import time

          g = Github(os.environ['GH_TOKEN'])
          data_dir = os.environ['DATA_DIR']
          
          try:
              # Mevcut repo-info.json'ƒ± y√ºkle veya olu≈ütur
              repo_info_path = f"{data_dir}/repo-info.json"
              if os.path.exists(repo_info_path):
                  with open(repo_info_path, 'r') as f:
                      existing_data = json.load(f)
              else:
                  existing_data = []
              
              existing_repos = {repo['name']: repo for repo in existing_data}
              updated_repos = []
              
              for repo in g.get_user().get_repos(type='all'):
                  try:
                      repo_dir = f"{data_dir}/repos/{repo.name}"
                      os.makedirs(repo_dir, exist_ok=True)
                      
                      # Trafik verilerini topla
                      views_data = {"views": [], "count": 0, "uniques": 0}
                      clones_data = {"clones": [], "count": 0, "uniques": 0}
                      
                      # Views verisi
                      try:
                          traffic = repo.get_views_traffic()
                          views_data = {
                              "views": [{
                                  "timestamp": v.timestamp.isoformat(),
                                  "count": v.count,
                                  "uniques": v.uniques
                              } for v in traffic["views"]],
                              "count": traffic["count"],
                              "uniques": traffic["uniques"]
                          }
                          with open(f"{repo_dir}/views.json", "w") as f:
                              json.dump(views_data, f, indent=2)
                      except Exception as e:
                          print(f"‚ö†Ô∏è Views error for {repo.name}: {str(e)}")
                      
                      # Clones verisi
                      try:
                          traffic = repo.get_clones_traffic()
                          clones_data = {
                              "clones": [{
                                  "timestamp": c.timestamp.isoformat(),
                                  "count": c.count,
                                  "uniques": c.uniques
                              } for c in traffic["clones"]],
                              "count": traffic["count"],
                              "uniques": traffic["uniques"]
                          }
                          with open(f"{repo_dir}/clones.json", "w") as f:
                              json.dump(clones_data, f, indent=2)
                      except Exception as e:
                          print(f"‚ö†Ô∏è Clones error for {repo.name}: {str(e)}")
                      
                      # Repo bilgisini g√ºncelle veya olu≈ütur
                      repo_info = existing_repos.get(repo.name, {
                          "name": repo.name,
                          "full_name": repo.full_name,
                          "private": repo.private,
                          "updated_at": repo.updated_at.isoformat()
                      })
                      repo_info.update({
                          "last_updated": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                          "has_views": len(views_data["views"]) > 0,
                          "has_clones": len(clones_data["clones"]) > 0
                      })
                      updated_repos.append(repo_info)
                      
                      time.sleep(1)
                      
                  except Exception as e:
                      print(f"‚ùå Error processing {repo.name}: {str(e)}")
              
              # G√ºncellenmi≈ü veriyi yaz
              with open(repo_info_path, 'w') as f:
                  json.dump(sorted(updated_repos, key=lambda x: x['name']), f, indent=2)
              
              print(f"‚úÖ Successfully processed {len(updated_repos)} repositories")
              
          except Exception as e:
              print(f"üî• Critical error: {str(e)}")
              raise
          EOF

      - name: Commit and push changes
        run: |
          # Git ayarlarƒ±
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          
          # Deƒüi≈üiklikleri ekle
          git add docs/data/
          
          # Commit mesajƒ±
          commit_msg="üìä Updated traffic data $(date '+%Y-%m-%d %H:%M')"
          
          # Atomic commit ve push
          if git diff-index --quiet HEAD -- docs/data/repos; then
            echo "No changes in traffic data to commit"
          else
            git commit -m "$commit_msg"
            git pull --rebase origin main
            git push origin main
          fi