name: GitHub Traffic Data Collector

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  fetch-traffic-data:
    runs-on: ubuntu-latest
    concurrency: 
      group: traffic-data-${{ github.ref }}
      cancel-in-progress: true
    
    steps:
      - name: Checkout with deep cleanup
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          fetch-depth: 0
          clean: true

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          echo "pygithub==1.59.0" > requirements.txt
          pip install -r requirements.txt

      - name: Atomic data preparation
        run: |
          # Tüm eski verileri atomik şekilde sil
          rm -rf docs/data/
          mkdir -p docs/data/repos
          echo "[]" > docs/data/repo-info.json
          echo "DATA_DIR=docs/data" >> $GITHUB_ENV

      - name: Collect traffic data
        env:
          GH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
        run: |
          python - <<EOF
          from github import Github
          import os
          import json
          import time
          from datetime import datetime

          g = Github(os.environ['GH_TOKEN'])
          data_dir = os.environ['DATA_DIR']
          
          try:
              repo_data = []
              repos = list(g.get_user().get_repos(type='all'))
              
              for repo in repos:
                  try:
                      repo_dir = os.path.join(data_dir, "repos", repo.name)
                      os.makedirs(repo_dir, exist_ok=True)
                      
                      # Views verisi
                      views_path = os.path.join(repo_dir, "views.json")
                      try:
                          views = repo.get_views_traffic()
                          with open(views_path, 'w') as f:
                              json.dump({
                                  "views": [{
                                      "timestamp": v.timestamp.isoformat(),
                                      "count": v.count,
                                      "uniques": v.uniques
                                  } for v in views["views"]],
                                  "count": views["count"],
                                  "uniques": views["uniques"]
                              }, f)
                      except Exception as e:
                          print(f"⚠️ Views error for {repo.name}: {str(e)}")
                          open(views_path, 'a').close()  # Boş dosya oluştur
                      
                      # Clones verisi
                      clones_path = os.path.join(repo_dir, "clones.json")
                      try:
                          clones = repo.get_clones_traffic()
                          with open(clones_path, 'w') as f:
                              json.dump({
                                  "clones": [{
                                      "timestamp": c.timestamp.isoformat(),
                                      "count": c.count,
                                      "uniques": c.uniques
                                  } for c in clones["clones"]],
                                  "count": clones["count"],
                                  "uniques": clones["uniques"]
                              }, f)
                      except Exception as e:
                          print(f"⚠️ Clones error for {repo.name}: {str(e)}")
                          open(clones_path, 'a').close()  # Boş dosya oluştur
                      
                      # Repo metadata
                      repo_data.append({
                          "name": repo.name,
                          "full_name": repo.full_name,
                          "private": repo.private,
                          "updated_at": datetime.now().isoformat(),
                          "last_checked": datetime.now().isoformat()
                      })
                      
                      time.sleep(2)  # Güçlü rate limit koruması
                      
                  except Exception as e:
                      print(f"❌ Repo processing failed: {repo.name} - {str(e)}")
              
              # Atomik repo-info güncelleme
              with open(os.path.join(data_dir, "repo-info.json"), 'w') as f:
                  json.dump(repo_data, f, indent=2)
              
              print(f"✅ Successfully processed {len(repos)} repositories")
              
          except Exception as e:
              print(f"🔥 Critical failure: {str(e)}")
              raise
          EOF

      - name: Atomic git operations
        run: |
          # Tüm dosya izinlerini düzelt
          find docs/data -type f -exec chmod 644 {} \;
          find docs/data -type d -exec chmod 755 {} \;
          
          # Git ayarları
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          
          # Tüm değişiklikleri ekle
          git add --all docs/data/
          
          # Commit oluştur
          git commit -m "📊 Atomic traffic data update [skip ci]" || echo "No changes to commit"
          
          # Yeniden başlatılmış senkronizasyon
          git fetch origin main
          git reset --soft origin/main
          [ -z "$(git status --porcelain)" ] || git commit -m "📊 Traffic data update"
          git push origin main --force-with-lease